# W01 D04 (2025-09-21)

## ✅ 오늘 한 일

### BE
- **Reservation/Order 부하 테스트 준비**
  - 왜? → SLA 검증을 위해 VU 증가(50 → 200 → 500 → 1000) 시 성능/실패율 확인 필요.
  - 그래서 → `day04_hold_order.js` K6 스크립트 작성. 좌석 선점 → 주문/취소 플로우에 traceId, Idempotency-Key 적용.
  - 결과 → 각 VU 단계별 K6 실행 및 Jaeger 트레이스 확인 완료.

- **DB/Redis 병목 추적**
  - 왜? → 실패율이 높아진 원인을 식별해야 함.
  - 그래서 → Jaeger 트레이스로 reservation-api `db.is-sold` 구간에서 800ms~1s 이상 지연 확인. Redis `hold.setnx`는 상대적으로 짧으나 부하 증가 시 커넥션 포화 가능성 확인.
  - 결과 → **DB 커넥션 풀 및 is-sold 쿼리 직렬화가 가장 큰 병목**임을 확인.

- **DB max_connections 조정**
  - 왜? → 기본 151 제한으로 VU 증가 시 HikariCP 커넥션 부족 발생.
  - 그래서 → root 권한으로 `SET GLOBAL max_connections=500;` 적용.
  - 결과 → 500까지 정상 반영 확인.

### Infra/테스트
- **K6 부하 테스트 (50, 200, 500, 1000 VU)**
  - 50 VU: p95 ≈ 1s, 실패율 ≈ 57%
  - 200 VU: p95 ≈ 790ms, 실패율 ≈ 96%
  - 500 VU: p95 ≈ 3.17s, 실패율 ≈ 95%
  - 1000 VU: p95 ≈ 9.26s, 실패율 ≈ 93%, `connection forcibly closed` 다수 발생
  - 결과 → SLA 기준(p95 < 300ms, fail < 0.5%) **전 구간 미달성**. Throughput은 증가하였으나 에러율 급증.

- **Jaeger 분산 트레이싱**
  - Reservation → Catalog API 호출까지 trace 연결 확인.
  - 주요 병목: `db.is-sold` 쿼리 구간 (최대 ~1s).
  - Redis setnx 및 Catalog SSE publish는 상대적으로 경미.

---

## 📚 배운 점
- 단순 커넥션 풀 확장만으로는 **직렬화되는 DB 쿼리 병목**을 해결할 수 없음.
- 고 VU 환경에서 **OS 소켓/포트 한계**가 실제 에러(`connection forcibly closed`)로 이어짐.
- Redis를 통한 캐싱/락 제어 최적화가 필수.

---

## 📝 내일(Day05) 예정 작업
- **DB 병목 최적화**
  - `is-sold` 쿼리 Redis 캐시 적용 검토.
  - HikariCP 풀 사이즈 확대 및 DB read/write 분리 고려.
- **Redis/서버 튜닝**
  - Redis maxclients, pool 설정 최적화.
  - EC2 OS 레벨 TCP/소켓 파라미터 조정 (`somaxconn`, `port_range`, `ulimit`).
- **재부하 테스트**
  - 200, 500, 1000 VU 시 다시 실행 → 튜닝 전후 성능 비교.
